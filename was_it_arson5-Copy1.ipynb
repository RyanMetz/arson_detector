{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below removes the annoying app bar thing at the bottom of a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$('.nbp-app-bar').toggle()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$('.nbp-app-bar').toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "#import pysal as ps\n",
    "#from pysal.contrib.viz import mapping as maps\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below makes it so pandas will show me all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell loads the spatialite extention to sqlite. I got the code from the spatialite mailing list\n",
    "https://groups.google.com/d/msg/spatialite-users/o0jUwMUqx_g/OEat2JTUAAAJ\n",
    "I can get it to work without geopandas. With geopandas imported it kills the ipython kernel within seconds. Ironic! Without one, the other is useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn = sqlite3.connect(':memory:') \n",
    "#conn.enable_load_extension(True) \n",
    "#conn.execute(\"SELECT load_extension('mod_spatialite')\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code for importing all the sql data came from: https://www.dataquest.io/blog/python-pandas-databases/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"./FPA_FOD_20170508.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is if you want to read the data in as tuples\n",
    "\n",
    "#cur = conn.cursor()\n",
    "#cur.execute(\"SELECT * FROM fires;\")\n",
    "#results = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_sql_query(\"SELECT * FROM fires;\", conn)\n",
    "#this grabs the whole db and puts it into a df using the sqlite3.Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since pandas can't handle the geometry information the Shape column is useless anyway, I'm going to drop it. It lives on in the original sqlite db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['Shape'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.STAT_CAUSE_DESCR.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are entries in my target column that I can't use so I am dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(df_all[df_all['STAT_CAUSE_DESCR'] == 'Missing/Undefined'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to create a new df, df_pred, by dropping columns from the FPA_FOD data. I'm going to read that into a csv so I have it for later, and then stop using the full set. I will keep the full set on my SSD, of course. I am making these decisions based on the data atlas located here: https://www.kaggle.com/davideanastasia/contour-map-of-us-wildfire-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['FIRE_CODE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to drop features that I don't care about and then do feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['OBJECTID', 'FPA_ID', 'SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM',\n",
    "                  'NWCG_REPORTING_AGENCY', 'NWCG_REPORTING_UNIT_ID',\n",
    "                  'NWCG_REPORTING_UNIT_NAME', 'SOURCE_REPORTING_UNIT',\n",
    "                  'SOURCE_REPORTING_UNIT_NAME', 'LOCAL_FIRE_REPORT_ID',\n",
    "                  'LOCAL_INCIDENT_ID', 'FIRE_NAME',\n",
    "                  'ICS_209_INCIDENT_NUMBER', 'ICS_209_NAME', 'MTBS_ID', 'MTBS_FIRE_NAME',\n",
    "                  'COMPLEX_NAME', 'FIRE_YEAR', 'DISCOVERY_TIME', \n",
    "                  'STAT_CAUSE_CODE', 'CONT_TIME', \n",
    "                  'FIRE_SIZE_CLASS', 'LATITUDE', 'LONGITUDE', 'OWNER_CODE', \n",
    "                  'OWNER_DESCR', 'COUNTY', 'FIPS_NAME'], axis=1)\n",
    "\n",
    "#at some point redo this. Instead of doing a drop just include all feats I want to keep. Much more readable, shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 columns with the dates for discovery and containment are in the Julian format so I will have to convert them into gregorian timestamps and then engineer a duration. I do think day of year discovered will have some predictive power and will keep that column. I will also engineer month and a day-of-week discovered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['START_DATE'] = pd.to_datetime(df_all['DISCOVERY_DATE'], unit='D', infer_datetime_format=True, origin='julian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['END_DATE'] = pd.to_datetime(df_all['CONT_DATE'], unit='D', infer_datetime_format=True, origin='julian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['DISCOVERY_DATE', 'CONT_DATE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['BURN_TIME'] = (df_all['END_DATE'] - df_all['START_DATE']).astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MONTH'] = pd.DatetimeIndex(df_all['START_DATE']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['DOW'] = pd.DatetimeIndex(df_all['START_DATE']).weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['CONT_DOY'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['END_DATE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['FOD_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['BURN_TIME'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(40,5))\n",
    "sns.countplot(x=df_all['BURN_TIME'].value_counts(), data=df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to make a new column to use as my target, \"Arson\". If the cause was arson the value will be 1, else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below works but it isn't vectorized and it takes a hot minute. Going to try to do something faster for practice.\n",
    "\n",
    "# def make_arson(dataframe):\n",
    "#     if dataframe['STAT_CAUSE_DESCR'] == 'Arson':\n",
    "#         val = 1\n",
    "#     else:\n",
    "#         val = 0\n",
    "#     return val\n",
    "#\n",
    "#\n",
    "# df_all['ARSON'] = df_all.apply(make_arson, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#humbug. df_all['ARSON'] = [x for x in df_all['STAT_CAUSE_DESCR'] if x =='Arson' x = 1 else 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_all['STAT_CAUSE_DESCR'] != 'Arson', 'ARSON'] = 0\n",
    "df_all.loc[df_all['STAT_CAUSE_DESCR'] == 'Arson', 'ARSON'] = 1\n",
    "\n",
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow that was a lot faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['ARSON'] = df_all['ARSON'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now That I've made the target column for arson I can drop the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['STAT_CAUSE_DESCR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.ARSON.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "281455/1713742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.42% of these fires were started by arsonists! Crazy. Also: that's a pretty unbalanced class. Hopefully that won't cause problems. Famous last words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over half of all the FIRE_CODE entries are nulls. DROPPED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['FIRE_CODE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to drop FIPS, because I think State will cover location and going all the way down to county risks overfitting on historic data. A county may have an arsonist in it for a time who may have been arrested, moved or died; using a coefficient for that county that was affected while the arsonist was acitive will decrease accuracy. This is also true in a state but given the differences in population between states and differenes in weather conditions I think it will be predictive and have a lower risk of over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['FIPS_CODE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't really need to do this because I'm going to label encode and then one-hot encode it later but that will make just doing one loop for all the things that need encoding simpler, if a little more time consuming to run. Worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MONTH'] = df_all['MONTH'].apply(lambda x: calendar.month_name[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops, ran it twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After much consideration I am going to drop the start date, keep the day-of-year, but transform it to be cyclic so the algorithms can see that 1 and 365 are actually closer than 60 and 365."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['START_DATE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to encode my categorical values. I can use one-hot encoding or get dummies and drop one column. For month and day-of-week there are only 12 and 7 categories, respectively, so for them I'll get dummies. For the other 2 I'll use one-hot because there are so categories and I don't want to dataframe that big considering how much modeling I'm doing, the ram required would get too big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to try impute data for BURN_TIME. I want to test to see if the data is missing at random. I'm going to check for a correlation between BURN_TIME and the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'm going to just drop the missing burn time values and then include it in my analysis. See what that gets me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn = df_all.drop(df_all[df_all['BURN_TIME'].isnull() == True].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.STATE.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_wburn.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to make the DISCOVERED_DOY cyclic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn['DOY_SIN'] = np.sin(df_wburn.DISCOVERY_DOY*(2.*np.pi/365))\n",
    "df_wburn['DOY_COS'] = np.cos(df_wburn.DISCOVERY_DOY*(2.*np.pi/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn = df_wburn.drop(['DISCOVERY_DOY'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to scale this. There are a ton of outliers so I'm going to use RobustScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robsca = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_wburn['BURN_TIME'] = robsca.fit_transform(df_wburn['BURN_TIME'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_wburn.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that with all the zeros in BURN_TIME it's a sparse matrix so robust scalar won't work. Sparse data often calls for MaxAbsScaler but that scales by the highest absolute value, and since there are outliers in both BURN_TIME and FIRE_SIZE I don't want to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn['BURN_TIME'] = ss.fit_transform(df_wburn['BURN_TIME'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_wburn.FIRE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robsca = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn['FIRE_SIZE'] = robsca.fit_transform(df_wburn['FIRE_SIZE'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_wburn.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.to_csv('./data_to_encode.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn = pd.read_csv('./data_to_encode.csv')\n",
    "print(df_wburn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OKAY. Now everything that needed to be is scaled and normalized. Time to encode my categorical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE BELOW WAS THE ORIGINAL PLAN BUT I SWITCHED TO ONE-HOT ENCODING EVERYTHING AND USING PCA TO REDUCE DIMENSIONALITY.\n",
    "\n",
    "I need to drop 1 dummy variable for each of the features I just got dummies from. I'm choosing Wednesday because it's the middle of the weekdays, of which there are 5 vs just 2 weekends (I believe that the ratio of causes that fires started on weekend days had will be different from weekdays. I am hoping this will help with interpretation.) I'm choosing January essentially at random, it's the first value which is what get_dummies has as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_vars=['MONTH','DOW']\n",
    "# for var in categorical_vars:\n",
    "#     cat_list='var'+'_'+var\n",
    "#     cat_list = pd.get_dummies(df_all[var], prefix=var, drop_first=False)\n",
    "#     df_all1=df_all.join(cat_list)\n",
    "#     df_all=df_all1\n",
    "\n",
    "#DECIDED TO DO ONE-HOT ENCODING ON EVERYTHING AND THEN USE PCA TO DEAL WITH THE COLLINIERITY PROBLEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = LabelEncoder()\n",
    "oh_enc = OneHotEncoder()\n",
    "\n",
    "need_encoding = [df_wburn['STATE'], df_wburn['MONTH'], df_wburn['DOW']]\n",
    "\n",
    "for feat in need_encoding:\n",
    "    feat_int_encoded = lab_enc.fit_transform(feat)\n",
    "    feat_int_encoded_reshape = feat_int_encoded.reshape(len(feat_int_encoded), 1) \n",
    "    feat_onehot_encoded = oh_enc.fit_transform(feat_int_encoded_reshape)\n",
    "    df_feat = pd.DataFrame(feat_onehot_encoded.toarray())\n",
    "    df_wburn2 = pd.merge(df_wburn, df_feat, left_index=True, right_index=True)\n",
    "    df_wburn = df_wburn2\n",
    "\n",
    "df_wburn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.STATE.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.DOW.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.MONTH.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.drop(['STATE', 'MONTH', 'DOW'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote the dataframe to .csv as this is what I'm going to perform PCA on and I wanted it as a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.to_csv('./final_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn = pd.read_csv('./final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Futher down you can see there's a strange phenomenon where the first PCA feature after transformation accounts for over 99.99% of the variation. In the next cells I tried to discover why that might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.corrcoef(df_wburn['FIRE_SIZE'], df_wburn['BURN_TIME']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a nice looking dataframe for machine learning. To deal with the all that dimensionality and collinearity I'm going to use PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df_wburn.columns:\n",
    "    print(np.corrcoef(df_wburn['ARSON'], df_wburn[i])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was thinking that one un-transformed feature might account for nearly all the variation so I checked corrcoeffs above. It's actually nicely distributed. The largest one is 0.3, which is not strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I looked to see if having both DOY_SIN and DOY_COS in the data was causing the weirdness. It was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nosin = df_wburn.drop(['DOY_SIN'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nosin.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_nosin = PCA()\n",
    "pca_nosin.fit(df_nosin.drop(['ARSON'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_exp_nosin = pca_nosin.explained_variance_ratio_\n",
    "cum_var_exp_nosin = np.cumsum(var_exp_nosin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pca_nosin.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# HERE IS THE BASIC PLOT\n",
    "\n",
    "# Plot the cumulative explained variance\n",
    "component_number = list(range(1, 75))\n",
    "plt.plot(component_number, cum_var_exp_nosin, lw=3)\n",
    "\n",
    "# NOW MAKE IT LOOK PRETTY\n",
    "\n",
    "# Add horizontal lines at y=0 and y=100\n",
    "plt.axhline(y=0, linewidth=5, color='grey', ls='dashed')\n",
    "plt.axhline(y=1, linewidth=3, color='grey', ls='dashed')\n",
    "\n",
    "# Set the x and y axis limits\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([1,74])\n",
    "ax.set_ylim([-0.05,1.05])\n",
    "\n",
    "# Label the axes\n",
    "ax.set_ylabel('cumulative variance explained', fontsize=16)\n",
    "ax.set_xlabel('component', fontsize=16)\n",
    "\n",
    "# Make the tick labels bigger\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(12) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(12) \n",
    "    \n",
    "# Add title\n",
    "ax.set_title('component vs cumulative variance explained\\n', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cum_var_exp_nosin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking out DOY_SIN actually increased the percentage of variation accounted for by the first PCA feature. So I went back to using the full dataframe. At this point, all the categorical data has been one-hot encoded, the PCA transformation has taken care of the collinearity that encoding causes, the numerical data has all been scaled, no correlation coefficients were very strong, and taking out one of the DOY columns basically did nothing. I conclude that something **extremely** improbable has occured, and because I have a good grasp on statistics I know that happens. I am moving on to do a PCA transformation on the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_wburn = PCA()\n",
    "pca_wburn.fit(df_wburn.drop(['ARSON'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells are from the PCA lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_exp_wburn = pca_wburn.explained_variance_ratio_\n",
    "cum_var_exp_wburn = np.cumsum(var_exp_wburn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pca_wburn.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# HERE IS THE BASIC PLOT\n",
    "\n",
    "# Plot the cumulative explained variance\n",
    "component_number = list(range(1, 76))\n",
    "plt.plot(component_number, cum_var_exp_wburn, lw=3)\n",
    "\n",
    "# NOW MAKE IT LOOK PRETTY\n",
    "\n",
    "# Add horizontal lines at y=0 and y=100\n",
    "plt.axhline(y=0, linewidth=5, color='grey', ls='dashed')\n",
    "plt.axhline(y=1, linewidth=3, color='grey', ls='dashed')\n",
    "\n",
    "# Set the x and y axis limits\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([1,74])\n",
    "ax.set_ylim([-0.05,1.05])\n",
    "\n",
    "# Label the axes\n",
    "ax.set_ylabel('cumulative variance explained', fontsize=16)\n",
    "ax.set_xlabel('component', fontsize=16)\n",
    "\n",
    "# Make the tick labels bigger\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(12) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(12) \n",
    "    \n",
    "# Add title\n",
    "ax.set_title('component vs cumulative variance explained\\n', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't trust that result at all. But I have tried a bunch of different ways to catch something going wrong with it. I dropped one of my cyclical DOY columns - nothing. I scaled and normalized both my numeric columns: fire size and burn time - nothing. I checked the corrcoeffs of each feature against Arson: the biggest one is 0.3 - nothing there either. I checked to see what the correlation between BURN_TIME and FIRE_SIZE is, it's 0.1 - nothing. I have looked over the code, which is quite simple and would be hard to screw up in such a way that it would still run, several times and found no errors. I suppose it's possible that something extraordinarily improbable has occurred here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cum_var_exp_wburn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll keep 4 of my pca components for now. That keeps 99.999984% of my variance explained while dropping almost all of my variables. This solves the high dimensionality my data had after one-hot encoding. It also is going to make everything run much faster than if I had needed to keep a large number of features. After I've gotten to the point where I'm scoring models I'll try a few other numbers of PCA features to use, all low to keep my dimensionality down.\n",
    "\n",
    "**UPDATE:** Setled on 6 PCA features after looking at scores for several different numbers of kept features on a logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to make my training and testing sets. Then I'll transform with PCA and use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_wburn.drop(['ARSON'], axis=1)\n",
    "y = df_wburn['ARSON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_6 = PCA(n_components=6)\n",
    "pca_6.fit(X_train)\n",
    "Xt_train = pca_6.transform(X_train)\n",
    "Xt_test = pca_6.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About half of the code for these models came from : http://scikit-learn.org/stable/auto_examples/ensemble/plot_feature_transformation.html#sphx-glr-auto-examples-ensemble-plot-feature-transformation-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839936340794759"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of estimators for Random Trees, Random Forest, and Gradient Boosting Classifier.** 10 is a common choice so I went with that. This will be tuned later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Trees Embedding piped to Logistic Regression.** This was not part of my original plan but I found it online and it looked cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('randomtreesembedding', RandomTreesEmbedding(max_depth=4, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           random_state=42, sp...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt = RandomTreesEmbedding(max_depth=4, n_estimators=n_estimator,\n",
    "    random_state=42)\n",
    "\n",
    "rt_lm = LogisticRegression()\n",
    "pipeline = make_pipeline(rt, rt_lm)\n",
    "pipeline.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839936340794759"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=4, n_estimators=n_estimator)\n",
    "rf.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839936340794759"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd = GradientBoostingClassifier(n_estimators=n_estimator)\n",
    "grd.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839936340794759"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanmetz/anaconda3/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8402470064367741"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes.** For all binary features a Bernoulli kernel is used, for categorical data, a multinomial. My data is neither so I went with a Gaussian kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(Xt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.617020116962889"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calibrated Classifier with LinearSVC.** LinearSVC doesn't have a predict_probas method. Calibrated Classifer not only improves it's performance, it has a predict_probas method, so I use it here. It requires an extra split. This model's computational demands increase dramatically with dimensionality so I went down to using only 2 PCA features for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_svc, X_test_svc, y_train_svc, y_test_svc = train_test_split(X, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components=2)\n",
    "pca2.fit(X_train_svc)\n",
    "Xt_train_svc = pca2.transform(X_train_svc)\n",
    "Xt_test_svc = pca2.transform(X_test_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanmetz/anaconda3/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/Users/ryanmetz/anaconda3/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/Users/ryanmetz/anaconda3/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "/Users/ryanmetz/anaconda3/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/Users/ryanmetz/anaconda3/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/Users/ryanmetz/anaconda3/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "/Users/ryanmetz/anaconda3/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "/Users/ryanmetz/anaconda3/envs/ipykernel_py3/lib/python3.6/site-packages/sklearn/calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0),\n",
       "            cv=2, method='sigmoid')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_class_lsvc = CalibratedClassifierCV(lsvc, cv=2, method='sigmoid')\n",
    "cal_class_lsvc.fit(Xt_train_svc, y_train_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8409444248385695"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_class_lsvc.score(Xt_test_svc, y_test_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell was run and an ROC curve was generated below. It was terrible so I commented this all out so it wouldn't be re-run if I end up restarting this kernel and going through everything again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xt_train_small, Xt_train_lr, y_train_small, y_train_lr = train_test_split(Xt_train,\n",
    "#                                                             y_train,\n",
    "#                                                             test_size=0.5)\n",
    "\n",
    "# grd_enc_lm = GradientBoostingClassifier(n_estimators=n_estimator)\n",
    "# grd_lm = LogisticRegression()\n",
    "# grd_enc = OneHotEncoder()\n",
    "\n",
    "# grd.fit(Xt_train_small, y_train_small)\n",
    "# grd_enc.fit(grd.apply(Xt_train_small)[:, :, 0])\n",
    "# grd_lm.fit(grd_enc.transform(grd.apply(Xt_train_lr)[:, :, 0]), y_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SVC()\n",
    "# clf.fit(Xt_train, y_train) commented out because this takes waaaaay to long to run on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented this out because I'm going to use roc2() from now on\n",
    "\n",
    "# def roc(probas, true, step=0.01):\n",
    "    \n",
    "#     probas = probas[:,1]  \n",
    "#     true = true.values \n",
    "#     assert(len(probas) == len(true))\n",
    "    \n",
    "#     TPRs = [] # Setting up empty list of True Positive Rate\n",
    "#     FPRs = [] # Setting up empty list of False Positive Rate\n",
    "    \n",
    "#     for i in np.arange(0.0,1.0,step): # np.arange allows us to use step sizes that are decimals\n",
    "#         preds_class = probas > i # Numpy arrays have a feature called 'broadcasting.' Check the documentation: https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html to see what this does.\n",
    "#         TP = 0 \n",
    "#         FP = 0\n",
    "#         TN = 0\n",
    "#         FN = 0\n",
    "#         for index in range(len(preds_class)): # We're comparing each prediction with each true value here\n",
    "\n",
    "#             if preds_class[index] == 1 and true[index] == 1:\n",
    "#                 TP += 1\n",
    "#             elif preds_class[index] == 1 and true[index] == 0:\n",
    "#                 FP += 1\n",
    "#             elif preds_class[index] == 0 and true[index] == 0:\n",
    "#                 TN += 1 \n",
    "#             elif preds_class[index] == 0 and true[index] == 1:\n",
    "#                 FN += 1\n",
    "                \n",
    "#         TPR = TP/(TP + FN) # Calculating TPR and FPR and appending to our lists\n",
    "#         FPR = FP/(FP + TN)\n",
    "        \n",
    "#         TPRs.append(TPR)\n",
    "#         FPRs.append(FPR)\n",
    "         \n",
    "#     plt.rcParams['font.size'] = 14\n",
    "#     plt.plot(FPRs, TPRs, color=\"orange\")\n",
    "#     plt.plot([0,1],[0,1], color='navy', lw=2, linestyle='--')\n",
    "#     plt.xlim([0.0, 1.0])\n",
    "#     plt.ylim([0.0, 1.0])\n",
    "#     plt.title('Receiver Operating Characteristic')\n",
    "#     plt.xlabel(\"False Positive Rate\")\n",
    "#     plt.ylabel(\"True Positive Rate\")\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc(lr.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#roc(pipeline.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc(rf.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc(grd.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc(xgb.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#commented out so it can't be run again. This was terrible so I'm not going to use it, but if I go back and run\n",
    "#everything again I don't want to spend the few minutes this took to run, but I don't want to lose the graph.\n",
    "#roc(grd_lm.predict_proba(grd_enc.transform(grd.apply(X_test)[:, :, 0])), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow definitely don't use that one. I'm going to comment grd_lm out above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next 2 cells also comes from a GA lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc2(probas, true, step=0.01, plot=True):\n",
    "    \"\"\"\n",
    "    probas should be a numpy array of predict_probas\n",
    "    true is a pandas series of true labels\n",
    "    step is the step size for checking thresholds\n",
    "    plot is a boolean for whether we want to generate a plot\n",
    "    \"\"\"\n",
    "    \n",
    "    probas = probas[:,1]  # The output of predict_proba() is an array of the probabilities for every class, but we only want the probabilities for class 1\n",
    "    true = true.values    # We need to convert the class labels from a Pandas Series to a numpy array. We do this using the .values attribute\n",
    "    assert(len(probas) == len(true)) # We're making sure that our probabilities vector is the same length as our true class labesl vector\n",
    "    \n",
    "    TPRs = [] # Setting up empty list of True Positive Rate\n",
    "    FPRs = [] # Setting up empty list of False Positive Rate\n",
    "    \n",
    "    for i in np.arange(0.0,1.0,step): # np.arange allows us to use step sizes that are decimals\n",
    "        preds_class = probas > i # Numpy arrays have a feature called 'broadcasting.' Check the documentation: https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html to see what this does.\n",
    "        TP = 0 \n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for index in range(len(preds_class)): # We're comparing each prediction with each true value here\n",
    "\n",
    "            if preds_class[index] == 1 and true[index] == 1:\n",
    "                TP += 1\n",
    "            elif preds_class[index] == 1 and true[index] == 0:\n",
    "                FP += 1\n",
    "            elif preds_class[index] == 0 and true[index] == 0:\n",
    "                TN += 1 \n",
    "            elif preds_class[index] == 0 and true[index] == 1:\n",
    "                FN += 1\n",
    "                \n",
    "        TPR = TP/(TP + FN) # Calculating TPR and FPR and appending to our lists\n",
    "        FPR = FP/(FP + TN)\n",
    "        \n",
    "        TPRs.append(TPR)\n",
    "        FPRs.append(FPR)\n",
    "        \n",
    "    if plot: # Only generate a plot if plot == True\n",
    "        \n",
    "        plt.rcParams['font.size'] = 14\n",
    "        plt.plot(FPRs, TPRs, color=\"orange\")\n",
    "        plt.plot([0,1],[0,1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.show();\n",
    "        \n",
    "    return np.array(TPRs), np.array(FPRs) # We'll neet to have our TPRs and FPRs as arrays so we can use broadcasting in the next function.\n",
    "\n",
    "def sen_spec(probas, true, stat=\"sensitivity\", stat_val=0.5, step=0.01):\n",
    "    '''\n",
    "    This is the function that the assignment is asking for. We'll feed in our probas and true vectors as we do with the previous function, as well\n",
    "    as we are looking at, as well as the value of that stat that we want to find, and the step size for our roc function.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    stat = stat.lower() # turn the string into lowercase for ease of comparison\n",
    "    \n",
    "    assert(stat in [\"sensitivity\", \"specificity\"]) # Throw an error if the user did not write sensitivity or specificity\n",
    "    \n",
    "    TPRs, FPRs = roc2(probas, true, step=step, plot=False) # use our roc function to get vectors of TPR and FPR\n",
    "    \n",
    "    if stat == \"sensitivity\":\n",
    "        diffs = np.absolute(TPRs - stat_val) # We won't necessarily be able to find a threshold that gives the exact value we're looking for, but we can find the one that gets us the closest.\n",
    "        loc = np.argmin(diffs) # We want to find the index of the TPR that was closest to the value we specified\n",
    "        threshold = loc * step\n",
    "        sensitivity = TPRs[loc]\n",
    "        spec_corr = (1 - FPRs[loc])\n",
    "        \n",
    "        print(\"Sensitivity: {:.5f}%, Specificity: {:.5f}%, Threshold: {}%\".format(sensitivity*100, spec_corr*100, threshold*100))\n",
    "        return TPRs, FPRs\n",
    "    \n",
    "    elif stat == \"specificity\":\n",
    "        specificities = 1 - FPRs # FPR = 1 - specificity --> specificity = 1 - FPR\n",
    "        diffs = np.absolute(specificities - stat_val)\n",
    "        loc = np.argmin(diffs)\n",
    "        threshold = loc * step\n",
    "        specificity = specificities[loc]\n",
    "        sens_corr = (TPRs[loc])\n",
    "        \n",
    "        print(\"Specificity: {:.5f}%, Sensitivity: {:.5f}%, Threshold: {}%\".format(specificity*100, sens_corr*100, threshold*100))\n",
    "        return TPRs, FPRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y, x):\n",
    "    \n",
    "    auc = 0\n",
    "    for i in range(1,len(x)):\n",
    "        auc += ((y[i] + y[i-1])/2)*abs((x[i] - x[i-1]))\n",
    "        \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to re-run all the models for scoring with the above functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.9999319 , 0.99982975, 0.99965949, 0.99918278,\n",
       "        0.99897848, 0.99850177, 0.99775266, 0.9360188 , 0.86951784,\n",
       "        0.83093844, 0.79402751, 0.7652547 , 0.73672024, 0.70512122,\n",
       "        0.67253473, 0.6426042 , 0.62190139, 0.59316263, 0.55900981,\n",
       "        0.52131572, 0.47664124, 0.43700627, 0.39951648, 0.37547671,\n",
       "        0.3493258 , 0.32242577, 0.28987333, 0.25565241, 0.21731136,\n",
       "        0.16957232, 0.11546581, 0.05621765, 0.02557205, 0.00769545,\n",
       "        0.0023495 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]),\n",
       " array([1.        , 0.99978587, 0.99951333, 0.99862435, 0.99658034,\n",
       "        0.99447145, 0.99156441, 0.98399185, 0.7633623 , 0.6365235 ,\n",
       "        0.57252983, 0.5177634 , 0.47892725, 0.44772207, 0.4175616 ,\n",
       "        0.38856913, 0.36502735, 0.34881804, 0.32816383, 0.3054721 ,\n",
       "        0.27842631, 0.25140647, 0.2275662 , 0.20790479, 0.19485559,\n",
       "        0.17905508, 0.16315725, 0.14510509, 0.12671551, 0.10672965,\n",
       "        0.08318138, 0.05601879, 0.02960891, 0.01368512, 0.00337424,\n",
       "        0.00138863, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc2(lr.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TPRs_lr, FPRs_lr = sen_spec(probas=lr.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n",
    "#this was with 5 pca feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TPRs_lr, FPRs_lr = sen_spec(probas=lr.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n",
    "# 7 PCA feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TPRs_lr, FPRs_lr = sen_spec(probas=lr.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n",
    "# 8 pca feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"by-hand gridsearch\" shows that 6 PCA features gives the best sensitivity. Could be a local maxima but I'm not willing to make the data array even bigger than 8 given how many rows I have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5abb7ca43134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTPRs_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFPRs_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msen_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"specificity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#with 6 pca feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-4c59f282faf0>\u001b[0m in \u001b[0;36msen_spec\u001b[0;34m(probas, true, stat, stat_val, step)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"sensitivity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"specificity\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Throw an error if the user did not write sensitivity or specificity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mTPRs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFPRs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# use our roc function to get vectors of TPR and FPR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sensitivity\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-4c59f282faf0>\u001b[0m in \u001b[0;36mroc2\u001b[0;34m(probas, true, step, plot)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpreds_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mTP\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0mpreds_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mFP\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mpreds_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TPRs_lr, FPRs_lr = sen_spec(probas=lr.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n",
    "#with 6 pca feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_lr, FPRs_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = lr.predict(Xt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, lr_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad bad bad. Gotta balance. No way around it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This \"pipeline\" was a random trees embedding with a logistic regression performed on that output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(pipeline.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_rt, FPRs_rt = sen_spec(probas=pipeline.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_rt, FPRs_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(rf.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_rf, FPRs_rf = sen_spec(probas=rf.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_rf, FPRs_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is Gradient Boosted Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(grd.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_grd, FPRs_grd = sen_spec(probas=grd.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_grd, FPRs_grd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(xgb.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_xgb, FPRs_xgb = sen_spec(probas=xgb.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_xgb, FPRs_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Gaussian Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(gnb.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_gnb, FPRs_gnb = sen_spec(probas=gnb.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_gnb, FPRs_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_1 = PCA(n_components=1)\n",
    "# pca_1.fit(X_train)\n",
    "# Xt_train_svm = pca_1.transform(X_train)\n",
    "# Xt_test_svm = pca_1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SVC(probability=True)\n",
    "# clf.fit(Xt_train_svm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc2(clf.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPRs_svc, FPRs_svc = sen_spec(probas=svc.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc(TPRs_svc, FPRs_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC is too computationally demanding for this laptop without CUDA compiling and running it on my GPU. Going to have to do that in the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(calclass_lsvc.predict_proba(Xt_test_svc), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I screwed up by calibrating and training on the same data set, which is fatal to this technique. I'll have to go fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_calcla_lsvc, FPRs_gnb = sen_spec(probas=calclass_lsvc.predict_proba(Xt_test_svc), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would appear that having my classes unbalanced, cases of Arson make up only 16% of the instances in my sample. Has truly come back to haunt me. I will now deal with that in various ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_wburn.ARSON.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: downsample majority class\n",
    "\n",
    "df_minority = df_wburn[df_wburn['ARSON']==1]\n",
    "df_majority = df_wburn[df_wburn['ARSON']==0]\n",
    " \n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=59948,     # to match minority class\n",
    "                                 random_state=42) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.ARSON.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = df_downsampled.drop(['ARSON'], axis=1)\n",
    "yd = df_downsampled['ARSON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_down, X_test_down, y_train_down, y_test_down = train_test_split(Xd, yd, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_6_down = PCA(n_components=6)\n",
    "pca_6_down.fit(X_train_down)\n",
    "Xdt_train = pca_6_down.transform(X_train_down)\n",
    "Xdt_test = pca_6_down.transform(X_test_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially I tested on down-sampled data. This is wrong. I need to train on my downsampled data and then test against the full data set. Rather and doubling the number of cells below this I went back and re-did it the proper way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_down = LogisticRegression()\n",
    "lr_down.fit(Xdt_train, y_train_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_down.score(Xt_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_down = RandomTreesEmbedding(max_depth=4, n_estimators=n_estimator,\n",
    "    random_state=42)\n",
    "\n",
    "rt_lm_down = LogisticRegression()\n",
    "pipeline_down = make_pipeline(rt_down, rt_lm_down)\n",
    "pipeline_down.fit(Xdt_train, y_train_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_down = RandomForestClassifier(max_depth=4, n_estimators=n_estimator)\n",
    "rf_down.fit(Xdt_train, y_train_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_down = GradientBoostingClassifier(n_estimators=n_estimator)\n",
    "grd_down.fit(Xdt_train, y_train_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_down = XGBClassifier()\n",
    "xgb_down.fit(Xdt_train, y_train_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_down = GaussianNB()\n",
    "gnb.fit(Xdt_train, y_train_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_down = LinearSVC(fit_intercept=False, random_state=42)\n",
    "lsvc_down.fit(Xdt_train, y_train_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(lr_down.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_lr_down, FPRs_lr_down = sen_spec(probas=lr_down.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_lr_down, FPRs_lr_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not exactly the sensitivity score I was looking for. AUC-ROC score is at 76.6%, not really a change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_down_preds = lr_down.predict(Xt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(pipeline_down.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_pipeline_down, FPRs_pipeline_down = sen_spec(probas=pipeline_down.predict_proba(Xt_test), true=y_test, stat=\"sensitivity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_pipeline_down, FPRs_pipeline_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That actually got worse. Something is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_down_preds = pipeline_down.predict(Xt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((Xdt_train).shape)\n",
    "print((Xdt_test).shape)\n",
    "print((y_train_down).value_counts())\n",
    "print((y_test_down).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sizes and value counts are right. I'm not sure what's going on here. I can't find a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(rf_down.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_rf_down, FPRs_rf_down = sen_spec(probas=rf_down.predict_proba(Xt_test), true=y_test, stat=\"sensitivity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_rf_down, FPRs_rf_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting the downsampled data provided an rf with 1% higher sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_down_preds = rf_down.predict(Xt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(grd_down.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_grd_down, FPRs_grd_down = sen_spec(probas=grd_down.predict_proba(Xt_test), true=y_test, stat=\"specificity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_grd_down, FPRs_grd_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_down_preds = grd_down.predict(Xt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc2(xgb_down.predict_proba(Xt_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPRs_xgb_down, FPRs_xgb_down = sen_spec(probas=xgb_down.predict_proba(Xt_test), true=y_test, stat=\"sensitivity\", stat_val = 0.99, step=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(TPRs_xgb_down, FPRs_xgb_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_down_preds = xgb_down.predict(Xt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, lr_down_preds))\n",
    "print(classification_report(y_test, pipeline_down_preds))\n",
    "print(classification_report(y_test, rf_down_preds))\n",
    "print(classification_report(y_test, grd_down_preds))\n",
    "print(classification_report(y_test, xgb_down_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Balance Method 2:** up-sampling the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wburn.ARSON.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority_up = df_wburn[df_wburn.ARSON==0]\n",
    "df_minority_up = df_wburn[df_wburn.ARSON==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority_up, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=355013,    # to match majority class\n",
    "                                 random_state=42) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_up = pd.concat([df_majority_up, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_up.ARSON.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xu = df_up.drop(['ARSON'], axis=1)\n",
    "yu = df_up['ARSON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_u, X_test_u, yu_train, yu_test = train_test_split(Xu, yu, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_6_up = PCA(n_components=6)\n",
    "pca_6_up.fit(X_train_u)\n",
    "Xu_train = pca_6_up.transform(X_train_u)\n",
    "Xu_test = pca_6_up.transform(X_test_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ipykernel_py3]",
   "language": "python",
   "name": "conda-env-ipykernel_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
