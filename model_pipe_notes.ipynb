{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$('.nbp-app-bar').toggle()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$('.nbp-app-bar').toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have models instantiated into vars. make a list of tuple of models. set up predictions_train. add cross_val_predictions to the dataframe, fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ['logistic', lr],  #these are all tuples, \"models\" is the list of them\n",
    "    ['pipeline', pipeline],\n",
    "    ['random forest', rf],\n",
    "    ['gradient boosting', grd],\n",
    "    ['XGBoost', xgb],\n",
    "    ['GaussianNB', gnb],\n",
    "    ['calibrated LinearSVC', cal_class_lsvc]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = pd.DataFrame()\n",
    "for model_tup in models:\n",
    "    name, model = model_tup\n",
    "    predictions_train[name + ' _pred')] = cross_val_predict(model)\n",
    "    model.fit(X_train, y_train)\n",
    "predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how correlated are the predictions? We want them to have different predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(predictions_train.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm probably going to have a ton of similar opinions, what am I gonna do? Polynomial features! Don't do it for the super slow ones. Cut down to 3 PCA features. Look at corr_heatmap. For the models that are the most highly correlated, choose the slower of the 2 and do the polynomial thing. For those models make a pipeline that starts with the polynomial features and passes them to the model. The other ones don't need a pipe because we pass PCA feats to them directly (instead of making a PCA pipe for each of the models, which would add to run time and mess everything up. include_bias=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomial pipeline example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_pipe = Pipeline([\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),\n",
    "    ('logistic regression', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_agg = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_agg.fit(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = pd.DataFrame()\n",
    "for model_tup in models:\n",
    "    name, model = model_tup\n",
    "    predictions_test[name + ' _pred'] = model.predict(X_test)\n",
    "predictions_test.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ada_agg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-268d2c908a63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mada_agg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ada_agg' is not defined"
     ]
    }
   ],
   "source": [
    "ada_agg.score(predictions_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ipykernel_py3]",
   "language": "python",
   "name": "conda-env-ipykernel_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
